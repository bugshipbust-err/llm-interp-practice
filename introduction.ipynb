{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bed8205-3d51-4f06-9626-fa84fcfc41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79021e06-ad54-4f0a-88c1-aea8d97e57db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "gpt2_small: HookedTransformer = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b07ecc-e80d-4038-9178-f3df4a8356d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformerConfig:\n",
       "{'NTK_by_parts_factor': 8.0,\n",
       " 'NTK_by_parts_high_freq_factor': 4.0,\n",
       " 'NTK_by_parts_low_freq_factor': 1.0,\n",
       " 'NTK_original_ctx_len': 8192,\n",
       " 'act_fn': 'gelu_new',\n",
       " 'attention_dir': 'causal',\n",
       " 'attn_only': False,\n",
       " 'attn_scale': np.float64(8.0),\n",
       " 'attn_scores_soft_cap': -1.0,\n",
       " 'attn_types': None,\n",
       " 'checkpoint_index': None,\n",
       " 'checkpoint_label_type': None,\n",
       " 'checkpoint_value': None,\n",
       " 'd_head': 64,\n",
       " 'd_mlp': 3072,\n",
       " 'd_model': 768,\n",
       " 'd_vocab': 50257,\n",
       " 'd_vocab_out': 50257,\n",
       " 'decoder_start_token_id': None,\n",
       " 'default_prepend_bos': True,\n",
       " 'device': device(type='cuda'),\n",
       " 'dtype': torch.float32,\n",
       " 'eps': 1e-05,\n",
       " 'experts_per_token': None,\n",
       " 'final_rms': False,\n",
       " 'from_checkpoint': False,\n",
       " 'gated_mlp': False,\n",
       " 'init_mode': 'gpt2',\n",
       " 'init_weights': False,\n",
       " 'initializer_range': np.float64(0.02886751345948129),\n",
       " 'load_in_4bit': False,\n",
       " 'model_name': 'gpt2',\n",
       " 'n_ctx': 1024,\n",
       " 'n_devices': 1,\n",
       " 'n_heads': 12,\n",
       " 'n_key_value_heads': None,\n",
       " 'n_layers': 12,\n",
       " 'n_params': 84934656,\n",
       " 'normalization_type': 'LNPre',\n",
       " 'num_experts': None,\n",
       " 'original_architecture': 'GPT2LMHeadModel',\n",
       " 'output_logits_soft_cap': -1.0,\n",
       " 'parallel_attn_mlp': False,\n",
       " 'positional_embedding_type': 'standard',\n",
       " 'post_embedding_ln': False,\n",
       " 'relative_attention_max_distance': None,\n",
       " 'relative_attention_num_buckets': None,\n",
       " 'rotary_adjacent_pairs': False,\n",
       " 'rotary_base': 10000,\n",
       " 'rotary_dim': None,\n",
       " 'scale_attn_by_inverse_layer_idx': False,\n",
       " 'seed': None,\n",
       " 'tie_word_embeddings': False,\n",
       " 'tokenizer_name': 'gpt2',\n",
       " 'tokenizer_prepends_bos': False,\n",
       " 'trust_remote_code': False,\n",
       " 'ungroup_grouped_query_attention': False,\n",
       " 'use_NTK_by_parts_rope': False,\n",
       " 'use_attn_in': False,\n",
       " 'use_attn_result': False,\n",
       " 'use_attn_scale': True,\n",
       " 'use_hook_mlp_in': False,\n",
       " 'use_hook_tokens': False,\n",
       " 'use_local_attn': False,\n",
       " 'use_normalization_before_and_after': False,\n",
       " 'use_split_qkv_input': False,\n",
       " 'window_size': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ba95cd-2c5b-4ba2-a1bb-59f17dfcbe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model with loss and logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cf4e85-d637-4669-a2dd-8512057e2161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.2622, device='cuda:0', grad_fn=<DivBackward0>) torch.Size([2, 19, 50257])\n"
     ]
    }
   ],
   "source": [
    "text = [\"Hello world, this is somebody who has never touched a keyboard. What do you think?\", \"should i keep touching grass, or should i start coding? \"]\n",
    "# text --> batch or a string\n",
    "logits = gpt2_small(text, return_type=\"logits\")   \n",
    "loss = gpt2_small(text, return_type=\"loss\")   # prediction loss for the entire batch\n",
    "# logits, loss = gpt2_small(text, return_type=\"both\")   # return_type=None does not calculate the logits(faster way when we need only the intermediate activation) \n",
    "\n",
    "print(loss, logits.size())   # loss: floating, logits: [batch_size, no_tokens, d_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f118e5-7985-4c62-9d2a-e8b5a21af9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3fe2f45-ac10-4c5c-aee3-f18149df0495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "torch.Size([2, 768])\n",
      "torch.Size([12, 768, 64])\n",
      "torch.Size([768, 3072])\n"
     ]
    }
   ],
   "source": [
    "# weight lables: \"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/full-merm.svg\"\n",
    "input_ids = [2029, 220]\n",
    "\n",
    "print(len(gpt2_small.blocks))   # no of blocks\n",
    "print(gpt2_small.embed.forward(input_ids).size())   # returns token embeddings for the id [batch_size, d_model]  \n",
    "print(gpt2_small.blocks[0].attn.W_Q.size())   # getting attention block weights [n_heads, d_model, d_head]\n",
    "print(gpt2_small.blocks[11].mlp.W_in.size())  # MLP in transformation matrix [d_model, d_mlp]\n",
    "\n",
    "# alternately gpt2_small.W_K, gpt2_small.W_out, etc work aswell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1416b189-f4d0-467a-8d74-71e928619873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360a2223-aee5-4658-b1ac-f99ce4375e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<|endoftext|>', 'Hello', ' world', ',', ' this', ' is', ' somebody', ' who', ' has', ' never', ' touched', ' a', ' keyboard', '.', ' What', ' do', ' you', ' think', ' about', ' it', '?'], ['<|endoftext|>', 'should', ' i', ' keep', ' touching', ' grass', ',', ' or', ' should', ' i', ' start', ' coding', '?', ' ']]\n",
      "tensor([[15496,   995,    11,   428,   318,  8276,   508,   468,  1239, 12615,\n",
      "           257, 10586,    13,  1867,   466,   345,   892,   546,   340,    30],\n",
      "        [21754,  1312,  1394, 15241,  8701,    11,   393,   815,  1312,   923,\n",
      "         19617,    30,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256]],\n",
      "       device='cuda:0')\n",
      "<|endoftext|>Hello world this is\n"
     ]
    }
   ],
   "source": [
    "# print(gpt2_small.tokenizer)   # get tokenizer details\n",
    "print(gpt2_small.to_str_tokens(text))   # returns tokens\n",
    "print(gpt2_small.to_tokens(text, prepend_bos=False))   # converts to token ids\n",
    "print(gpt2_small.to_string([50256, 15496,   995,   428,   318]))   # converts to string\n",
    "\n",
    "# use prepend_bos=False in methods like to_tokens, model.forward, etc to disable adding the \"endoftext\"\n",
    "# token in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99289e2d-5c0b-402a-b5eb-4e525f8820e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello world, this is somebody who has never touched a keyboard. What do you think about it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f0df42-654f-4d1f-87fb-248d9f43e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits: Tensor = gpt2_small(text, return_type=\"logits\")\n",
    "prediction = logits.argmax(dim=-1).squeeze()\n",
    "\n",
    "tokenized_txt = gpt2_small.to_tokens(text).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa12722-092d-44a1-9dd1-32850b904113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50256, 15496,   995,    11,   428,   318,  8276,   508,   468,  1239,\n",
      "        12615,   257, 10586,    13,  1867,   466,   345,   892,   546,   340,\n",
      "           30], device='cuda:0') \n",
      " tensor([198,  11,  11, 198, 318, 616, 508, 468, 587, 587, 257, 983, 878, 314,\n",
      "        318, 345, 892,  30, 428,  30, 198], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_txt, \"\\n\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e56999d5-cf7e-414e-afca-24120af26eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  -->  ,\n",
      "318  -->   is\n",
      "508  -->   who\n",
      "468  -->   has\n",
      "257  -->   a\n",
      "345  -->   you\n",
      "892  -->   think\n",
      "30  -->  ?\n",
      "correct predictions:  8\n"
     ]
    }
   ],
   "source": [
    "# finding the no of correctly predicted tokens\n",
    "correct = 0\n",
    "for idx, pred in enumerate(prediction[:-1]):   # loops runs till the second last element\n",
    "    if pred == tokenized_txt[idx+1]:           # idx+1 to skip first token, cuz its bos-token\n",
    "        print(pred.item(), \" --> \", gpt2_small.to_string(pred.item()))\n",
    "        correct += 1\n",
    "print(\"correct predictions: \", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfbec2a5-ab94-401e-a0da-62032556a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing attention patterns\n",
    "\n",
    "import circuitvis\n",
    "\n",
    "gpt2_text = \"Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets.\"\n",
    "gpt2_tokens = gpt2_small.to_tokens(gpt2_text)\n",
    "gpt2_logits, gpt2_cache = gpt2_small.run_with_cache(gpt2_tokens, remove_batch_dim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2be7b0aa-435e-40e6-9570-24b3c4a69e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformer_lens.ActivationCache.ActivationCache'>\n",
      "torch.Size([12, 33, 33])\n",
      "Layer 0 Head Attention Patterns:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m gpt2_str_tokens \u001b[38;5;241m=\u001b[39m gpt2_small\u001b[38;5;241m.\u001b[39mto_str_tokens(gpt2_text)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer 0 Head Attention Patterns:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m display(\u001b[43mcv\u001b[49m\u001b[38;5;241m.\u001b[39mattention\u001b[38;5;241m.\u001b[39mattention_patterns(\n\u001b[1;32m      8\u001b[0m     tokens\u001b[38;5;241m=\u001b[39mgpt2_str_tokens, \n\u001b[1;32m      9\u001b[0m     attention\u001b[38;5;241m=\u001b[39mattention_pattern,\n\u001b[1;32m     10\u001b[0m     attention_head_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL0H\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m12\u001b[39m)],\n\u001b[1;32m     11\u001b[0m ))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(gpt2_cache))\n",
    "attention_pattern = gpt2_cache[\"pattern\", 0]\n",
    "print(attention_pattern.shape)\n",
    "gpt2_str_tokens = gpt2_small.to_str_tokens(gpt2_text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
