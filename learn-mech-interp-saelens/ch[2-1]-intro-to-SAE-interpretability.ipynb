{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229b90a6-a5e1-434a-ae45-8c8eef863b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F\n",
    "from tabulate import tabulate\n",
    "import numpy\n",
    "import random\n",
    "from pprint import pprint\n",
    "from einops import einsum\n",
    "\n",
    "from typing import Any, Callable, Literal, TypeAlias\n",
    "from jaxtyping import Float, Int\n",
    "\n",
    "from IPython.display import HTML, IFrame, display\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import circuitsvis as cv\n",
    "import sae_lens\n",
    "from sae_lens import SAE, ActivationsStore, HookedSAETransformer, LanguageModelSAERunnerConfig\n",
    "from sae_lens.loading.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens.utils import get_act_name, test_prompt, to_numpy\n",
    "\n",
    "from test_support import show_token_scores, show_topk_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467f5a48-1ac3-4c69-a78b-2dab6fb40157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x766ddb796e90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c2617a-1912-4a81-a21d-f78a479d590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SHOW AVAILABLE MODELS\n",
    "\n",
    "\n",
    "# metadata_rows = [\n",
    "#     [data.model, len(data.saes_map)]           # [data.model, data.release, data.repo_id, len(data.saes_map)]\n",
    "#     for data in get_pretrained_saes_directory().values()\n",
    "# ]\n",
    "\n",
    "# print(\n",
    "#     tabulate(\n",
    "#         sorted(metadata_rows, key=lambda x: x[0]),\n",
    "#         headers=[\"model\", \"n_saes\"],\n",
    "#         tablefmt=\"simple_outline\",\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f42f67-d2f9-4a5a-8d57-ba2003788575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SHOW SAE MODEL INFO\n",
    "\n",
    "# def format_value(value):\n",
    "#     return (\n",
    "#         \"{{{0!r}: {1!r}, ...}}\".format(*next(iter(value.items())))\n",
    "#         if isinstance(value, dict)\n",
    "#         else repr(value)\n",
    "#     )\n",
    "\n",
    "\n",
    "# release = get_pretrained_saes_directory()[\"gpt2-small-res-jb\"]\n",
    "\n",
    "# print(\n",
    "#     tabulate(\n",
    "#         [[k, format_value(v)] for k, v in release.__dict__.items()],\n",
    "#         headers=[\"Field\", \"Value\"],\n",
    "#         tablefmt=\"simple_outline\",\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a828ab-1982-4c0f-becd-35860035e4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "24576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/happyuser/anaconda3/envs/mech-interp/lib/python3.10/site-packages/sae_lens/saes/sae.py:249: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gpt2: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gpt2-small\")\n",
    "\n",
    "gpt2_sae, cfg_dict, sparsity = SAE.from_pretrained_with_cfg_and_sparsity(\n",
    "                                                    release=\"gpt2-small-res-jb\",\n",
    "                                                    sae_id=\"blocks.7.hook_resid_pre\",\n",
    "                                                )\n",
    "\n",
    "# pprint(cfg_dict)\n",
    "print(cfg_dict[\"d_sae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c187c31-2352-40b9-a174-2d60f1550a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dashboard(\n",
    "    sae_release=\"gpt2-small-res-jb\",\n",
    "    sae_id=\"blocks.7.hook_resid_pre\",\n",
    "    latent_idx=0,\n",
    "    width=800,\n",
    "    height=600,\n",
    "):\n",
    "    release = get_pretrained_saes_directory()[sae_release]\n",
    "    neuronpedia_id = release.neuronpedia_id[sae_id]\n",
    "\n",
    "    url = f\"https://neuronpedia.org/{neuronpedia_id}/{latent_idx}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "    print(url)\n",
    "    display(IFrame(url, width=width, height=height))\n",
    "\n",
    "\n",
    "# latent_idx = 9    # not every new is the same, the new which interests a neuron could be different from a new in your mind\n",
    "# latent_idx = 24111    # CNN neuron. highly sparse latent, so is interpretable af\n",
    "# latent_idx = 13    # a mild concpet level feature[activations_density < 0.05]. activates for words like victory, win, winning, and similar kind of shit\n",
    "# latent_idx = 67    # activates on country's decisions, government policies and like shit. high concept feature[high activations density].\n",
    "\n",
    "latent_idx = random.randint(0, gpt2_sae.cfg.d_sae)\n",
    "# display_dashboard(latent_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1198bfa6-48fb-4983-84bc-0fcf3f6fe6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN: |ï¿½| RANK: 44527, PROB: 1.0305602725357854e-11\n",
      "PROB: 69.55%  TOKEN: | priority|\n",
      "PROB: 9.21%  TOKEN: | effort|\n",
      "PROB: 5.60%  TOKEN: | issue|\n",
      "PROB: 4.13%  TOKEN: | challenge|\n",
      "PROB: 3.17%  TOKEN: | goal|\n",
      "PROB: 2.33%  TOKEN: | concern|\n",
      "PROB: 1.93%  TOKEN: | focus|\n",
      "PROB: 1.48%  TOKEN: | approach|\n",
      "PROB: 1.37%  TOKEN: | policy|\n",
      "PROB: 1.22%  TOKEN: | initiative|\n"
     ]
    }
   ],
   "source": [
    "# RUNNING SAEs\n",
    "\n",
    "prompt = \"Mitigating the risk of extinction from AI should be a global\"\n",
    "answer = \" priority\"\n",
    "\n",
    "# test_prompt(prompt, answer, gpt2)\n",
    "show_token_scores(gpt2, prompt, 101)\n",
    "show_topk_preds(gpt2, prompt, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c0a59-2fc8-440c-a698-e8ce97bffd45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
