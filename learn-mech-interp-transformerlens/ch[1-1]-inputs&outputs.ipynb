{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f88110a-b909-4b2e-993d-8534740e24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5727539d-a5e1-42e0-96f3-06adb29a9862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "gpt2 = transformer_lens.HookedTransformer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b879fab0-d9ed-4462-881f-d82111cea7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256, 24619,   460,  1650,   319, 46054]], device='cuda:0') \n",
      " ['<|endoftext|>', 'cats', ' can', ' sit', ' on', ' mats']\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "text = \"cats can sit on mats\"\n",
    "tokens = gpt2.to_tokens(text)\n",
    "print(tokens, \"\\n\", gpt2.to_str_tokens(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e504ef24-b979-45e4-b042-dad7d3ceb0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 50257])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get logits\n",
    "logits, cache = gpt2.run_with_cache(tokens)\n",
    "logits.size()    # [batch_size, seq_len, d_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a0a57d-642c-4629-b8f2-da2651b70922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to probability distrib and argmax it(models normal use a probabilistic selection approach)\n",
    "probs = logits.softmax(dim=-1)\n",
    "most_likely_next_tokens = gpt2.tokenizer.batch_decode(probs.argmax(dim=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82ed318-c145-44ef-88d1-837736f55d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', '.', ' be', ' on', ' their', ' and']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_next_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca3fcd7-b7e8-4209-afe8-74edf7485bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', '.', ' be', ' on', ' their', ' and']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24470bf8-8463-48f3-9865-e1f07b3d388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_final_token = gpt2.to_string(logits[0, -1].argmax())\n",
    "most_likely_final_token"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
