{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb831dfd-1174-4a60-8686-c0d291bdb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "from transformer_lens import utils\n",
    "import torch\n",
    "import gdown\n",
    "from einops import einsum\n",
    "import circuitsvis as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b55aebe-f968-4c52-9d5a-5f088993b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "933f8350-fb21-4363-a186-24acd48b6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "$ 2-layer model\n",
    "$ attention only\n",
    "$ no layer-normalization and biases\n",
    "$ positional embeddings are added to each query and key vectors in the attention layer(not token embeddings).\n",
    "  so no position data in the value matrix hence also not in the residual-stream[line: shortformer]\n",
    "\"\"\"\n",
    "\n",
    "cfg = HookedTransformerConfig(\n",
    "    d_model=768,\n",
    "    d_head=64,\n",
    "    n_heads=12,\n",
    "    n_layers=2,\n",
    "    n_ctx=2048,\n",
    "    d_vocab=50278,\n",
    "    attention_dir=\"causal\",\n",
    "    attn_only=True, # defaults to False\n",
    "    tokenizer_name=\"EleutherAI/gpt-neox-20b\", \n",
    "    seed=398,\n",
    "    use_attn_result=True,\n",
    "    normalization_type=None, # defaults to \"LN\", i.e. layernorm with weights & biases\n",
    "    positional_embedding_type=\"shortformer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abfb632-f2ca-4f43-960b-b086698a0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = \"/home/happyuser/main/3m/jupyter/transformerlens-practice/learn-mech-interp/essentials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8475e5e-3da9-4dbe-b6e2-3eaeb46d615f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HookedTransformer(cfg)\n",
    "pretrained_weights = torch.load(weights_dir+\"/essentialsewk26ptl.part\", map_location=\"cuda\")\n",
    "model.load_state_dict(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920c5a90-a409-4f74-9e00-ea69a601b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = model.run_with_cache(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9503b94-1f23-4242-83cb-e5ef25b61969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.attn.hook_result', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.attn.hook_result', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_post'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.cache_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44de86cb-d2dd-4228-bd8c-d551c0b82b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "'   ','   '.'   '-'   ' of'   ' and'   ' the'   ' a'   ' to'   ' ('   "
     ]
    }
   ],
   "source": [
    "for item in logits[0, -1].argsort(dim=-1, descending=True)[:10]:    # 0 is \\n\n",
    "    print(f\"'{model.to_string(item)}'\", end=\"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d683ee6-721b-4d2b-aceb-4d20fd55a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_store = torch.zeros((model.cfg.n_layers, model.cfg.d_head), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45172ed2-7d79-4455-b528-65d3008ee597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_hook(value_tensor, hook):\n",
    "    value_store[hook.layer(), :] = value_tensor[0, 0, 0, :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fabe6be-575c-4b41-b666-6fc9022cf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_with_hooks(\n",
    "    model.to_tokens(\"\"),\n",
    "    return_type=None,\n",
    "    fwd_hooks=[\n",
    "        (\"blocks.0.attn.hook_v\", value_hook),\n",
    "        (\"blocks.1.attn.hook_v\", value_hook),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0716f78-c940-401f-b54f-4df2a90abd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value0 pass!\n",
      "value1 pass!\n"
     ]
    }
   ],
   "source": [
    "torch.testing.assert_close(value_store[0], (model.embed([0]) @ model.blocks[0].attn.W_V[0])[0], atol=1e-3, rtol=0)\n",
    "print(\"value0 pass!\")\n",
    "torch.testing.assert_close(value_store[1], cache[\"blocks.0.hook_resid_post\"][0, 0] @ model.blocks[1].attn.W_V[0], atol=1e-3, rtol=0)\n",
    "print(\"value1 pass!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74cd17-a72f-45cc-a401-205087501445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_contributions(value_store, W_U):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
